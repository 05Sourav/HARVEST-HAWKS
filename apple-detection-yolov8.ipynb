{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9334735,"sourceType":"datasetVersion","datasetId":5656414}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:28:16.311812Z","iopub.execute_input":"2024-09-07T01:28:16.312091Z","iopub.status.idle":"2024-09-07T01:28:31.991350Z","shell.execute_reply.started":"2024-09-07T01:28:16.312058Z","shell.execute_reply":"2024-09-07T01:28:31.990265Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\nfrom ultralytics import YOLO\n\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport pathlib\n%matplotlib inline\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:28:41.274864Z","iopub.execute_input":"2024-09-07T01:28:41.275275Z","iopub.status.idle":"2024-09-07T01:28:45.659336Z","shell.execute_reply.started":"2024-09-07T01:28:41.275237Z","shell.execute_reply":"2024-09-07T01:28:45.658345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat ../input/apple-quality-dataset/Apple_Detection.v1i.yolov8/data.yaml","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:28:45.660918Z","iopub.execute_input":"2024-09-07T01:28:45.661370Z","iopub.status.idle":"2024-09-07T01:28:46.656749Z","shell.execute_reply.started":"2024-09-07T01:28:45.661335Z","shell.execute_reply":"2024-09-07T01:28:46.655740Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the YAML file\nwith open('../input/apple-quality-dataset/Apple_Detection.v1i.yolov8/data.yaml', 'r') as f:\n    data_yaml = yaml.safe_load(f)\n\n# update YAML with absolute path to kaggle data. You must use absolute path, relative path won't work\ndata_yaml['train'] = '/kaggle/input/apple-quality-dataset/Apple_Detection.v1i.yolov8/train/images'\ndata_yaml['val'] = '/kaggle/input/apple-quality-dataset/Apple_Detection.v1i.yolov8/valid/images'\n\n# write to disk\nwith open('data.yaml', 'w') as f:\n    yaml.dump(data_yaml, f)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:28:54.193736Z","iopub.execute_input":"2024-09-07T01:28:54.194128Z","iopub.status.idle":"2024-09-07T01:28:54.206266Z","shell.execute_reply.started":"2024-09-07T01:28:54.194091Z","shell.execute_reply":"2024-09-07T01:28:54.205357Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = Path(\"../input/apple-quality-dataset/Apple_Detection.v1i.yolov8\")\nimages_dir = data_dir / \"train\" / \"images\"\nlabels_dir = data_dir / \"train\" / \"labels\"\n\nclass_names = data_yaml['names']\n\n# Read the image file paths and annotations\nimage_paths = list(images_dir.glob(\"*.jpg\"))\nlabel_paths = sorted(labels_dir.glob(\"*.txt\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:28:56.483369Z","iopub.execute_input":"2024-09-07T01:28:56.483765Z","iopub.status.idle":"2024-09-07T01:28:56.653219Z","shell.execute_reply.started":"2024-09-07T01:28:56.483728Z","shell.execute_reply":"2024-09-07T01:28:56.652517Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resolutions = []\n\nfor image_path in image_paths:\n    img = cv2.imread(str(image_path))\n    h, w, _ = img.shape\n    resolutions.append((w, h))\n\nunique_resolutions = set(resolutions)\nprint(\"Unique resolutions:\", unique_resolutions)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:28:58.469496Z","iopub.execute_input":"2024-09-07T01:28:58.469848Z","iopub.status.idle":"2024-09-07T01:29:00.226924Z","shell.execute_reply.started":"2024-09-07T01:28:58.469816Z","shell.execute_reply":"2024-09-07T01:29:00.225941Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Number of images to randomly select\nnum_images = 5\n\n# Get the list of all image files in the 'images' directory\nimage_files = [f for f in pathlib.Path(images_dir).iterdir() if f.is_file()]\n\n# Shuffle the list of image files\nrandom.shuffle(image_files)\n\n# Select the specified number of image files\nselected_image_files = image_files[:num_images]\n\nfor selected_image_file in selected_image_files:\n    demo_image = selected_image_file\n    # Get the corresponding label file\n    demo_label = pathlib.Path(labels_dir) / f\"{selected_image_file.stem}.txt\"\n\n    # Load the image using OpenCV's imread function\n    image = cv2.imread(str(demo_image))\n\n    # Get the list of class names from the 'data' dictionary\n    class_list = data_yaml['names']\n\n    # Define a list of colors to be used to draw bounding boxes\n    colors = [(0,189,255)] \n\n    # Get the height and width of the image\n    height, width, _ = image.shape\n\n    # Create an empty list T\n    T = []\n\n    # Open the label file 'demo_label' in read mode and process each line\n    with open(demo_label, \"r\") as file1:\n        for line in file1.readlines():\n            # Split the line into a list of strings\n            split = line.split(\" \")\n\n            # Get the class id from the first element of the split list\n            class_id = int(split[0])\n\n            # Get the color corresponding to the class id from the 'colors' list\n            color = colors[class_id]\n            clazz = class_list[class_id]\n\n            # Get the x, y, w, h bounding box coordinates from the split list\n            x, y, w, h = float(split[1]), float(split[2]), float(split[3]), float(split[4])\n\n            # Rescale the x, y, w, h values to the size of the image\n            box = [int((x - 0.5*w)* width), int((y - 0.5*h) * height), int(w*width), int(h*height)]\n\n            # Draw a rectangle on the image using the 'box' and 'color' values\n            cv2.rectangle(image, box, color, 2)\n\n            # Draw a filled rectangle for the class label on the image\n            cv2.rectangle(image, (box[0], box[1] - 20), (box[0] + box[2], box[1]), color, -1)\n\n            # Write the class label on the image\n            cv2.putText(image, class_list[class_id], (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,0))\n\n        # Show the image using matplotlib\n        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        # Optionally resize the image (commented out in code)\n        image = cv2.resize(image, (600, 600))\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:29:00.426984Z","iopub.execute_input":"2024-09-07T01:29:00.427302Z","iopub.status.idle":"2024-09-07T01:29:02.448123Z","shell.execute_reply.started":"2024-09-07T01:29:00.427269Z","shell.execute_reply":"2024-09-07T01:29:02.447232Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_model = YOLO('yolov8x.pt')","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:29:33.689476Z","iopub.execute_input":"2024-09-07T01:29:33.689865Z","iopub.status.idle":"2024-09-07T01:29:33.897831Z","shell.execute_reply.started":"2024-09-07T01:29:33.689830Z","shell.execute_reply":"2024-09-07T01:29:33.896916Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params = {\n    'data':'data.yaml',\n    'imgsz':640,\n    'epochs':50,\n    'optimizer':'auto',\n    'pretrained':True,\n    'lr0':0.01,\n    'lrf': 0.01,\n    'cos_lr': False\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-07T05:25:31.972146Z","iopub.execute_input":"2024-09-07T05:25:31.972608Z","iopub.status.idle":"2024-09-07T05:25:31.977923Z","shell.execute_reply.started":"2024-09-07T05:25:31.972569Z","shell.execute_reply":"2024-09-07T05:25:31.976936Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = baseline_model.train(**params)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:29:39.728690Z","iopub.execute_input":"2024-09-07T01:29:39.729589Z","iopub.status.idle":"2024-09-07T01:44:44.338208Z","shell.execute_reply.started":"2024-09-07T01:29:39.729545Z","shell.execute_reply":"2024-09-07T01:44:44.337166Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results.results_dict","metadata":{"execution":{"iopub.status.busy":"2024-09-07T01:45:00.030029Z","iopub.execute_input":"2024-09-07T01:45:00.030766Z","iopub.status.idle":"2024-09-07T01:45:00.037521Z","shell.execute_reply.started":"2024-09-07T01:45:00.030719Z","shell.execute_reply":"2024-09-07T01:45:00.036591Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls runs/detect/train2/val_batch*.jpg","metadata":{"execution":{"iopub.status.busy":"2024-09-06T21:34:20.372058Z","iopub.execute_input":"2024-09-06T21:34:20.372833Z","iopub.status.idle":"2024-09-06T21:34:21.510905Z","shell.execute_reply.started":"2024-09-06T21:34:20.372794Z","shell.execute_reply":"2024-09-06T21:34:21.509461Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params['hsv_h'] = 0.02\nparams['hsv_s'] = 0.50\nparams['hsv_v'] = 0.30\nparams['degrees'] = 5.0\nparams['translate'] = 0.05\nparams['scale'] = 0.3\nparams['shear'] = 0.0\nparams['perspective'] = 0.0\nparams['flipud'] = 0.0\nparams['fliplr'] = 0.30\nparams['mosaic'] = 0.50\nparams['mixup'] = 0.0\nparams['label_smoothing'] = 0.15\n#params['fl_gamma'] = 2\nparams['box'] = 10.0\nparams['cls'] = 2.0\nparams['dfl'] = 2.0","metadata":{"execution":{"iopub.status.busy":"2024-09-07T05:28:36.471714Z","iopub.execute_input":"2024-09-07T05:28:36.472132Z","iopub.status.idle":"2024-09-07T05:28:36.479332Z","shell.execute_reply.started":"2024-09-07T05:28:36.472094Z","shell.execute_reply":"2024-09-07T05:28:36.478278Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del params['fl_gamma']","metadata":{"execution":{"iopub.status.busy":"2024-09-07T05:29:39.459965Z","iopub.execute_input":"2024-09-07T05:29:39.460880Z","iopub.status.idle":"2024-09-07T05:29:39.465152Z","shell.execute_reply.started":"2024-09-07T05:29:39.460832Z","shell.execute_reply":"2024-09-07T05:29:39.464028Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params","metadata":{"execution":{"iopub.status.busy":"2024-09-07T05:29:49.470913Z","iopub.execute_input":"2024-09-07T05:29:49.471357Z","iopub.status.idle":"2024-09-07T05:29:49.478569Z","shell.execute_reply.started":"2024-09-07T05:29:49.471313Z","shell.execute_reply":"2024-09-07T05:29:49.477624Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yolo_tuned =  YOLO('runs/detect/train/weights/best.pt')\nresults_1 = yolo_tuned.train(**params)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T05:29:56.316042Z","iopub.execute_input":"2024-09-07T05:29:56.316487Z","iopub.status.idle":"2024-09-07T06:15:54.290192Z","shell.execute_reply.started":"2024-09-07T05:29:56.316445Z","shell.execute_reply":"2024-09-07T06:15:54.288972Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_1.results_dict","metadata":{"execution":{"iopub.status.busy":"2024-09-07T06:16:37.801973Z","iopub.execute_input":"2024-09-07T06:16:37.803174Z","iopub.status.idle":"2024-09-07T06:16:37.810204Z","shell.execute_reply.started":"2024-09-07T06:16:37.803122Z","shell.execute_reply":"2024-09-07T06:16:37.809216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Perform inference on an image\nresults = model('/kaggle/input/apple-quality-dataset/Apple_Detection.v1i.yolov8/valid/images/image.jpg')\n\n# Visualize the results\nfor result in results:\n    boxes = result.boxes  # Bounding boxes\n    \n    # Get the image\n    img = result.orig_img\n    \n    # Plot the bounding boxes\n    for box in boxes:\n        x1, y1, x2, y2 = box.xyxy[0]  # get box coordinates\n        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n    \n    # Display the image\n    plt.figure(figsize=(10, 10))\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T21:53:57.741924Z","iopub.execute_input":"2024-09-06T21:53:57.743049Z","iopub.status.idle":"2024-09-06T21:53:58.134305Z","shell.execute_reply.started":"2024-09-06T21:53:57.743006Z","shell.execute_reply":"2024-09-06T21:53:58.132868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls runs/detect/train/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}